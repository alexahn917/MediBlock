{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision, storage\n",
    "from google.cloud.vision import types\n",
    "\n",
    "# Use credentials for google client\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_annotations {\n",
      "  mid: \"/m/0fjkt\"\n",
      "  description: \"tongue\"\n",
      "  score: 0.9559205174446106\n",
      "  topicality: 0.9559205174446106\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/06pj2k\"\n",
      "  description: \"lip\"\n",
      "  score: 0.9437325596809387\n",
      "  topicality: 0.9437325596809387\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/0k0pj\"\n",
      "  description: \"nose\"\n",
      "  score: 0.8922653198242188\n",
      "  topicality: 0.8922653198242188\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/02cqfm\"\n",
      "  description: \"close up\"\n",
      "  score: 0.8645135164260864\n",
      "  topicality: 0.8645135164260864\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/0283dt1\"\n",
      "  description: \"mouth\"\n",
      "  score: 0.8446222543716431\n",
      "  topicality: 0.8446222543716431\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/0f9swq\"\n",
      "  description: \"chin\"\n",
      "  score: 0.8396998643875122\n",
      "  topicality: 0.8396998643875122\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/037p5b\"\n",
      "  description: \"cheek\"\n",
      "  score: 0.7462172508239746\n",
      "  topicality: 0.7462172508239746\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/013y0j\"\n",
      "  description: \"organ\"\n",
      "  score: 0.6916050910949707\n",
      "  topicality: 0.6916050910949707\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/0dzd8\"\n",
      "  description: \"neck\"\n",
      "  score: 0.6138295531272888\n",
      "  topicality: 0.6138295531272888\n",
      "}\n",
      "label_annotations {\n",
      "  mid: \"/m/023j4r\"\n",
      "  description: \"nail\"\n",
      "  score: 0.5883389115333557\n",
      "  topicality: 0.5883389115333557\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The name of the image file to annotate\n",
    "file_name = 'v2.jpg'\n",
    "\n",
    "# Loads the image into memory\n",
    "with io.open(file_name, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crop_hints_annotation {\n",
       "  crop_hints {\n",
       "    bounding_poly {\n",
       "      vertices {\n",
       "      }\n",
       "      vertices {\n",
       "        x: 299\n",
       "      }\n",
       "      vertices {\n",
       "        x: 299\n",
       "        y: 377\n",
       "      }\n",
       "      vertices {\n",
       "        y: 377\n",
       "      }\n",
       "    }\n",
       "    confidence: 0.29999998211860657\n",
       "    importance_fraction: 1.0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.crop_hints(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
